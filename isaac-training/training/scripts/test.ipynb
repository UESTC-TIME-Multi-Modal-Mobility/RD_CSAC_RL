{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5329402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290374\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops.layers.torch import Rearrange\n",
    "from model import ViT,ConvNet\n",
    "# Define the feature extractor network based on the given architecture\n",
    "# feature_extractor_network = nn.Sequential(\n",
    "#     nn.LazyConv2d(out_channels=4, kernel_size=[5, 3], padding=[2, 1]), nn.ELU(),\n",
    "#     nn.LazyConv2d(out_channels=16, kernel_size=[5, 3], stride=[2, 1], padding=[2, 1]), nn.ELU(),\n",
    "#     nn.LazyConv2d(out_channels=16, kernel_size=[5, 3], stride=[2, 2], padding=[2, 1]), nn.ELU(),\n",
    "#     nn.LazyConv2d(out_channels=16, kernel_size=[5, 3], stride=[2, 2], padding=[2, 1]), nn.ELU(),\n",
    "#     Rearrange(\"n c w h -> n (c w h)\"),\n",
    "#     nn.LazyLinear(128), nn.LayerNorm(128),\n",
    "# )\n",
    "feature_extractor_network = ConvNet()\n",
    "dummy_input = torch.randn(128, 1, 36, 4)  \n",
    "feature_extractor_network(dummy_input)\n",
    "# Calculate the number of parameters in the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# Count the parameters in the defined model\n",
    "#cnn =19376 (万)\n",
    "#vit =1020780 (百万)\n",
    "#ConvNet =290374 (30万)\n",
    "param_count = count_parameters(feature_extractor_network)\n",
    "print(param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ee2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 425618\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 加载模型\n",
    "checkpoint = torch.load(\"./checkpoint_85000.pt\", map_location=\"cpu\")\n",
    "\n",
    "# 如果是保存的 state_dict\n",
    "if isinstance(checkpoint, dict) and \"state_dict\" in checkpoint:\n",
    "    state_dict = checkpoint[\"state_dict\"]\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "\n",
    "# 统计参数数量\n",
    "total_params = sum(v.numel() for v in state_dict.values() if isinstance(v, torch.Tensor))\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "#vit Total parameters: 3091000\n",
    "#vit1 Total parameters: 1156024\n",
    "#cnn Total parameters: 177388\n",
    "#convNet Total parameters: 425618\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ae0242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensordict._td.TensorDict'>\n",
      "_StringKeys({'agents': TensorDict(\n",
      "    fields={\n",
      "        observation: TensorDict(\n",
      "            fields={\n",
      "                direction: Tensor(shape=torch.Size([512, 32, 1, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                dynamic_obstacle: Tensor(shape=torch.Size([512, 32, 1, 5, 10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                lidar: Tensor(shape=torch.Size([512, 32, 1, 36, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                state: Tensor(shape=torch.Size([512, 32, 8]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([512, 32]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        reward: Tensor(shape=torch.Size([512, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([512, 32]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True), 'stats': TensorDict(\n",
      "    fields={\n",
      "        collision: Tensor(shape=torch.Size([512, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        episode_len: Tensor(shape=torch.Size([512, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        reach_goal: Tensor(shape=torch.Size([512, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        return: Tensor(shape=torch.Size([512, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([512, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([512, 32]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True), 'info': TensorDict(\n",
      "    fields={\n",
      "        drone_state: Tensor(shape=torch.Size([512, 32, 1, 13]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([512, 32]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True), 'done': tensor([[[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]]]), 'terminated': tensor([[[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]]]), 'truncated': tensor([[[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]]])})\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 加载 tensordict_step_0.pt 文件\n",
    "tensordict = torch.load(\"tensordict_step_0.pt\", map_location=\"cpu\")\n",
    "print(type(tensordict))\n",
    "print(tensordict.keys() if hasattr(tensordict, 'keys') else dir(tensordict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f9daa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Detected that PyTorch and torchvision were compiled with different CUDA versions. PyTorch has CUDA Version=11.7 and torchvision has CUDA Version=11.8. Please reinstall the torchvision that matches your PyTorch install.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch cuda version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mcuda)\n",
      "File \u001b[0;32m~/sim/extscache/omni.pip.torch-2_0_1-2.0.2+105.1.lx64/torch-2-0-1/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodulefinder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/sim/extscache/omni.pip.torch-2_0_1-2.0.2+105.1.lx64/torch-2-0-1/torchvision/datasets/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optical_flow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stereo_matching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     CarlaStereo,\n\u001b[1;32m      4\u001b[0m     CREStereo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     SintelStereo,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcaltech\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Caltech101, Caltech256\n",
      "File \u001b[0;32m~/sim/extscache/omni.pip.torch-2_0_1-2.0.2+105.1.lx64/torch-2-0-1/torchvision/datasets/_optical_flow.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _read_png_16\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _read_pfm, verify_str_arg\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisionDataset\n",
      "File \u001b[0;32m~/sim/extscache/omni.pip.torch-2_0_1-2.0.2+105.1.lx64/torch-2-0-1/torchvision/io/__init__.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_load_gpu_decoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_GPU_VIDEO_DECODER\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     _HAS_GPU_VIDEO_DECODER \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/sim/extscache/omni.pip.torch-2_0_1-2.0.2+105.1.lx64/torch-2-0-1/torchvision/io/_load_gpu_decoder.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _load_library\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     _load_library(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/sim/extscache/omni.pip.torch-2_0_1-2.0.2+105.1.lx64/torch-2-0-1/torchvision/extension.py:107\u001b[0m\n\u001b[1;32m    102\u001b[0m             warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoadLibraryExW is missing in kernel32.dll\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mload_library(lib_path)\n\u001b[0;32m--> 107\u001b[0m \u001b[43m_check_cuda_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sim/extscache/omni.pip.torch-2_0_1-2.0.2+105.1.lx64/torch-2-0-1/torchvision/extension.py:80\u001b[0m, in \u001b[0;36m_check_cuda_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     t_minor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(t_version[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t_major \u001b[38;5;241m!=\u001b[39m tv_major \u001b[38;5;129;01mor\u001b[39;00m t_minor \u001b[38;5;241m!=\u001b[39m tv_minor:\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected that PyTorch and torchvision were compiled with different CUDA versions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch has CUDA Version=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_major\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_minor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and torchvision has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA Version=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtv_major\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtv_minor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease reinstall the torchvision that matches your PyTorch install.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m         )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _version\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Detected that PyTorch and torchvision were compiled with different CUDA versions. PyTorch has CUDA Version=11.7 and torchvision has CUDA Version=11.8. Please reinstall the torchvision that matches your PyTorch install."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torch cuda version:\", torch.version.cuda)\n",
    "print(\"torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NavRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
