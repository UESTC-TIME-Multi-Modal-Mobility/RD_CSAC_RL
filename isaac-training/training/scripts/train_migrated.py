'''
Author: zdytim zdytim@foxmail.com
Date: 2026-01-05 22:21:54
LastEditors: zdytim zdytim@foxmail.com
LastEditTime: 2026-01-05 22:21:55
FilePath: /NavRL/isaac-training/training/scripts/train_migrated.py
Description: è¿™æ˜¯é»˜è®¤è®¾ç½®,è¯·è®¾ç½®`customMade`, æ‰“å¼€koroFileHeaderæŸ¥çœ‹é…ç½® è¿›è¡Œè®¾ç½®: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
'''
"""
åŸå§‹è®­ç»ƒè„šæœ¬çš„è¿ç§»ç¤ºä¾‹
========================

å±•ç¤ºå¦‚ä½•å°†ç°æœ‰çš„ppo_vit_v3.pyè®­ç»ƒé€»è¾‘è¿ç§»åˆ°æ–°çš„æ¨¡å‹ç®¡ç†å™¨ã€‚

ä¸»è¦æ›´æ”¹ï¼š
1. å¯¼å…¥æ–°çš„æ¨¡å‹ç®¡ç†å™¨
2. æ›¿æ¢æ¨¡å‹åˆ›å»ºé€»è¾‘
3. ä½¿ç”¨ç»Ÿä¸€çš„æ£€æŸ¥ç‚¹ç®¡ç†
4. ä¿æŒåŸæœ‰çš„è®­ç»ƒå¾ªç¯ä¸å˜
"""

import torch
import torch.nn as nn
import hydra
from omegaconf import DictConfig
from tensordict import TensorDict
from torchrl.envs import ParallelEnv
from torchrl.collectors import SyncDataCollector
from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage

# å¯¼å…¥æ–°çš„æ¨¡å‹ç®¡ç†å™¨ - è¿™æ˜¯ä¸»è¦æ”¹åŠ¨
from models import create_navrl_model, load_pretrained_model

# å…¶ä»–å¯¼å…¥ä¿æŒä¸å˜
from env import NavigationEnv
from utils import make_batch, vec_to_world


def create_environment(cfg, device):
    """åˆ›å»ºç¯å¢ƒ - ä¿æŒåŸæœ‰é€»è¾‘"""
    print("ğŸ—ï¸  Creating environment...")
    
    env_fn = lambda: NavigationEnv(cfg)
    env = ParallelEnv(
        num_workers=cfg.env.num_envs,
        create_env_fn=env_fn,
        device=device
    )
    
    print(f"   âœ… Created with {cfg.env.num_envs} parallel environments")
    return env


def create_collector(env, model, cfg, device):
    """åˆ›å»ºæ•°æ®æ”¶é›†å™¨ - ä¿æŒåŸæœ‰é€»è¾‘"""
    print("ğŸ“Š Creating data collector...")
    
    # åˆ›å»ºæ”¶é›†å™¨
    collector = SyncDataCollector(
        env,
        model,
        frames_per_batch=cfg.frames_per_batch,
        total_frames=cfg.total_frames,
        device=device,
        storing_device=device,
    )
    
    print(f"   âœ… Collector ready: {cfg.frames_per_batch} frames/batch")
    return collector


def create_replay_buffer(cfg, device):
    """åˆ›å»ºç»éªŒå›æ”¾ç¼“å†²åŒº - ä¿æŒåŸæœ‰é€»è¾‘"""
    if not cfg.use_replay_buffer:
        return None
    
    print("ğŸ’¾ Creating replay buffer...")
    
    buffer = TensorDictReplayBuffer(
        storage=LazyMemmapStorage(cfg.buffer_size, device=device),
        batch_size=cfg.minibatch_size,
        pin_memory=False,
        prefetch=3,
    )
    
    print(f"   âœ… Buffer ready: {cfg.buffer_size} capacity")
    return buffer


@hydra.main(version_base=None, config_path="../cfg", config_name="train_ppo_vit")
def main(cfg: DictConfig):
    """
    ä¸»è®­ç»ƒå‡½æ•° - ä½¿ç”¨æ–°çš„æ¨¡å‹ç®¡ç†å™¨
    
    ä¸»è¦æ›´æ”¹ï¼š
    1. ä½¿ç”¨create_navrl_model()æ›¿ä»£ç›´æ¥å®ä¾‹åŒ–PPOVIT
    2. é€šè¿‡model_managerç®¡ç†æ¨¡å‹çŠ¶æ€
    3. ç»Ÿä¸€çš„æ£€æŸ¥ç‚¹åŠ è½½/ä¿å­˜
    """
    print("ğŸš€ NavRL Training with New Model Manager")
    print("=" * 60)
    
    # è®¾å¤‡é…ç½®
    device = torch.device(cfg.device)
    print(f"ğŸ”§ Using device: {device}")
    
    # 1. åˆ›å»ºç¯å¢ƒ
    env = create_environment(cfg, device)
    observation_spec = env.observation_spec
    action_spec = env.action_spec
    
    # 2. åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨ - ä¸»è¦æ”¹åŠ¨åœ¨è¿™é‡Œ
    print("ğŸ§  Creating model...")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä»æ£€æŸ¥ç‚¹æ¢å¤
    resume_checkpoint = getattr(cfg, 'resume_checkpoint', None)
    
    if resume_checkpoint and resume_checkpoint != "":
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model_manager = load_pretrained_model(
            checkpoint_path=resume_checkpoint,
            cfg=cfg,
            observation_spec=observation_spec,
            action_spec=action_spec,
            device=device,
            load_optimizer=True
        )
    else:
        # åˆ›å»ºæ–°æ¨¡å‹
        model_manager = create_navrl_model(
            cfg=cfg,
            observation_spec=observation_spec,
            action_spec=action_spec,
            device=device
        )
    
    # è·å–æ¨¡å‹å®ä¾‹
    model = model_manager.get_model()
    
    # æ‰“å°æ¨¡å‹æ‘˜è¦
    model_manager.print_model_summary()
    
    # 3. åˆ›å»ºæ•°æ®æ”¶é›†å™¨
    collector = create_collector(env, model, cfg, device)
    
    # 4. åˆ›å»ºç»éªŒå›æ”¾ç¼“å†²åŒºï¼ˆå¯é€‰ï¼‰
    replay_buffer = create_replay_buffer(cfg, device)
    
    # 5. è®­ç»ƒå¾ªç¯ - ä¿æŒåŸæœ‰é€»è¾‘
    print("ğŸƒ Starting training loop...")
    
    collected_frames = 0
    for i, data in enumerate(collector):
        # è®­ç»ƒæ­¥éª¤è®¡æ•°
        current_frames = data.numel()
        collected_frames += current_frames
        
        print(f"\nStep {i+1} - Frames: {current_frames} (Total: {collected_frames})")
        
        # è®¾ç½®è®­ç»ƒæ¨¡å¼
        model_manager.set_training_mode(True)
        
        # è®­ç»ƒæ›´æ–° - ä½¿ç”¨æ¨¡å‹çš„trainæ–¹æ³•
        with torch.cuda.amp.autocast(enabled=getattr(cfg, 'use_amp', True)):
            train_info = model.train(data)
        
        # è®°å½•è®­ç»ƒä¿¡æ¯
        if i % cfg.log_interval == 0:
            print("ğŸ“Š Training metrics:")
            for key, value in train_info.items():
                print(f"   {key}: {value:.4f}")
        
        # å¯é€‰ï¼šæ·»åŠ åˆ°ç»éªŒå›æ”¾ç¼“å†²åŒº
        if replay_buffer is not None:
            replay_buffer.extend(data.reshape(-1))
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if i > 0 and i % cfg.save_interval == 0:
            save_path = f"outputs/checkpoint_step_{collected_frames}.pt"
            model_manager.save_checkpoint(
                filepath=save_path,
                step=collected_frames,
                additional_info={
                    'training_step': i,
                    'collected_frames': collected_frames,
                    'train_info': train_info
                }
            )
            print(f"ğŸ’¾ Checkpoint saved: {save_path}")
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€»å¸§æ•°
        if collected_frames >= cfg.total_frames:
            print(f"ğŸ‰ Training completed! Total frames: {collected_frames}")
            break
    
    # 6. æœ€ç»ˆè¯„ä¼°
    print("\nğŸ” Final evaluation...")
    model_manager.set_training_mode(False)
    
    # ç®€å•è¯„ä¼°å¾ªç¯
    eval_rewards = []
    for eval_episode in range(10):
        td = env.reset()
        episode_reward = 0
        
        for _ in range(200):  # æœ€å¤§æ­¥æ•°
            with torch.no_grad():
                td = model(td)
                td = env.step(td)
                
                reward = td["next", "agents", "reward"].sum().item()
                episode_reward += reward
                
                if td["next", "terminated"].any():
                    break
        
        eval_rewards.append(episode_reward)
    
    avg_reward = sum(eval_rewards) / len(eval_rewards)
    print(f"ğŸ“Š Average evaluation reward: {avg_reward:.2f}")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_save_path = "outputs/final_model.pt"
    model_manager.save_checkpoint(
        filepath=final_save_path,
        step=collected_frames,
        additional_info={
            'final_eval_reward': avg_reward,
            'eval_rewards': eval_rewards,
            'training_completed': True
        }
    )
    
    print(f"ğŸ’¾ Final model saved: {final_save_path}")
    print("ğŸ‰ Training session completed successfully!")


# === è¿ç§»æŒ‡å— ===
"""
ä»ppo_vit_v3.pyè¿ç§»åˆ°æ–°æ¨¡å‹ç®¡ç†å™¨çš„æ­¥éª¤ï¼š

1. å¯¼å…¥æ›´æ”¹ï¼š
   OLD: from ppo_vit_v3 import PPOVIT
   NEW: from models import create_navrl_model, load_pretrained_model

2. æ¨¡å‹åˆ›å»ºï¼š
   OLD: model = PPOVIT(cfg, observation_spec, action_spec, device)
   NEW: model_manager = create_navrl_model(cfg, observation_spec, action_spec, device)
        model = model_manager.get_model()

3. æ£€æŸ¥ç‚¹åŠ è½½ï¼š
   OLD: model.load_full_checkpoint(checkpoint_path)
   NEW: model_manager = load_pretrained_model(checkpoint_path, cfg, obs_spec, act_spec, device)

4. æ£€æŸ¥ç‚¹ä¿å­˜ï¼š
   OLD: torch.save({'model_state_dict': model.state_dict(), ...}, path)
   NEW: model_manager.save_checkpoint(path, step=step, additional_info={...})

5. å‚æ•°ç®¡ç†ï¼š
   OLD: model.shared_features.freeze_vit_encoder()
   NEW: model_manager.freeze_vit_encoder()

ä¼˜åŠ¿ï¼š
- âœ… æ›´æ¸…æ™°çš„ä»£ç ç»“æ„
- âœ… ç»Ÿä¸€çš„æ¥å£
- âœ… æ›´å¥½çš„é”™è¯¯å¤„ç†
- âœ… è‡ªåŠ¨çš„å‚æ•°ç»Ÿè®¡å’Œç®¡ç†
- âœ… çµæ´»çš„é…ç½®é€‰é¡¹
"""


if __name__ == "__main__":
    main()