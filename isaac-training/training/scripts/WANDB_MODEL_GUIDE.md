# NavRL + wandb æ¨¡å‹ç®¡ç†å®Œæ•´æŒ‡å—

## ğŸ“Š wandb æ¨¡å‹ç®¡ç†åŠŸèƒ½æ¦‚è¿°

wandb æ”¯æŒå¼ºå¤§çš„æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’Œè·Ÿè¸ªåŠŸèƒ½ï¼ŒNavRL å·²å®Œå…¨é›†æˆä»¥ä¸‹åŠŸèƒ½ï¼š

### ğŸš€ æ ¸å¿ƒåŠŸèƒ½

1. **æ¨¡å‹ Artifacts**: è‡ªåŠ¨ç‰ˆæœ¬åŒ–æ¨¡å‹æ–‡ä»¶
2. **æ¨¡å‹æ³¨å†Œè¡¨**: ç”Ÿäº§çº§æ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†
3. **æ€§èƒ½è·Ÿè¸ª**: è®­ç»ƒæŒ‡æ ‡ä¸æ¨¡å‹ç‰ˆæœ¬å…³è”
4. **æ™ºèƒ½ä¸Šä¼ **: åŸºäºæ€§èƒ½é˜ˆå€¼çš„æ™ºèƒ½æ¨¡å‹ä¿å­˜
5. **ä¾¿æ·æ¢å¤**: ä» wandb ç›´æ¥åŠ è½½æ¨¡å‹è¿›è¡Œè®­ç»ƒæˆ–æ¨ç†

## ğŸ”§ å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€ä½¿ç”¨ - é›†æˆåˆ°ç°æœ‰è®­ç»ƒè„šæœ¬

```python
# å¯¼å…¥ wandb æ¨¡å‹å·¥å…·
from wandb_model_utils import upload_model_to_wandb, save_and_upload_best_model

# åœ¨åŸæœ‰çš„æ¨¡å‹ä¿å­˜ä»£ç åæ·»åŠ 
torch.save(policy.state_dict(), ckpt_path)

# ä¸Šä¼ åˆ° wandb
upload_model_to_wandb(
    model_state_dict=policy.state_dict(),
    step=training_step,
    model_alias="latest"
)
```

### 2. æ™ºèƒ½æœ€ä½³æ¨¡å‹ä¿å­˜

```python
# è¯„ä¼°åè‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
best_tracker = {'best_value': float('-inf'), 'best_step': 0}

eval_metrics = {"mean_reward": 85.2, "success_rate": 0.95}
is_new_best = save_and_upload_best_model(
    model_state_dict=policy.state_dict(),
    step=training_step,
    eval_metrics=eval_metrics,
    threshold_metric="mean_reward",
    best_value_tracker=best_tracker
)
```

### 3. ä» wandb æ¢å¤è®­ç»ƒ

```python
# ä» wandb artifact åŠ è½½æ¨¡å‹
from wandb_model_utils import download_model_from_wandb

model_path = download_model_from_wandb("username/project/model-name:best")
if model_path:
    policy.load_state_dict(torch.load(model_path))
    print("âœ… Model restored from wandb")
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
isaac-training/training/scripts/
â”œâ”€â”€ models/                          # æ–°çš„æ¨¡å‹ç®¡ç†å™¨
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ navrl_model.py              # ä¸»è¦æ¨¡å‹ç®¡ç†å™¨ (åŒ…å« wandb é›†æˆ)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ wandb_model_utils.py            # wandb å·¥å…·å‡½æ•° (è½»é‡çº§é›†æˆ)
â”œâ”€â”€ train_ppo_with_wandb.py         # é›†æˆç‰ˆè®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_with_wandb.py             # å®Œæ•´çš„ wandb è®­ç»ƒå™¨
â””â”€â”€ cfg/
    â””â”€â”€ wandb_model_config.yaml     # wandb é…ç½®ç¤ºä¾‹
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: è½»é‡çº§é›†æˆ (æ¨èç”¨äºç°æœ‰é¡¹ç›®)

**é€‚ç”¨äº**: å·²æœ‰è®­ç»ƒè„šæœ¬ï¼Œå¸Œæœ›æœ€å°æ”¹åŠ¨é›†æˆæ¨¡å‹ç®¡ç†

```bash
# 1. å¯¼å…¥å·¥å…·å‡½æ•°
from wandb_model_utils import upload_model_to_wandb

# 2. åœ¨ç°æœ‰ä¿å­˜ä»£ç åæ·»åŠ ä¸Šä¼ 
torch.save(model.state_dict(), path)
upload_model_to_wandb(model.state_dict(), step=step)

# 3. è¿è¡Œè®­ç»ƒ
python train_ppo.py  # ä½ çš„ç°æœ‰è®­ç»ƒè„šæœ¬
```

### åœºæ™¯ 2: å®Œæ•´é›†æˆ (æ¨èç”¨äºæ–°é¡¹ç›®)

**é€‚ç”¨äº**: æ–°é¡¹ç›®æˆ–æ„¿æ„é‡æ„è®­ç»ƒä»£ç 

```bash
# 1. ä½¿ç”¨æ–°çš„è®­ç»ƒè„šæœ¬
python train_ppo_with_wandb.py

# 2. æˆ–ä½¿ç”¨å®Œæ•´çš„è®­ç»ƒå™¨
python train_with_wandb.py

# 3. ä» wandb æ¢å¤è®­ç»ƒ
python train_ppo_with_wandb.py resume_checkpoint="user/project/model:best"
```

### åœºæ™¯ 3: ä½¿ç”¨æ–°æ¨¡å‹ç®¡ç†å™¨

**é€‚ç”¨äº**: å¸Œæœ›æ›´å¥½çš„ä»£ç ç»“æ„å’ŒåŠŸèƒ½

```python
from models import create_navrl_model

# åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
model_manager = create_navrl_model(cfg, obs_spec, act_spec, device)

# ä¿å­˜å¹¶ä¸Šä¼ æ¨¡å‹
model_manager.save_checkpoint(
    filepath="checkpoint.pt",
    step=1000,
    upload_to_wandb=True,
    wandb_alias="best"
)

# ä» wandb åŠ è½½
model_manager.load_from_wandb("user/project/model:latest")
```

## âš™ï¸ é…ç½®é€‰é¡¹

### åŸºç¡€ wandb é…ç½®

```yaml
wandb:
  project: "navrl-models"
  name: "ppo-vit-experiment"
  mode: "online"  # "offline", "disabled"

model_management:
  upload_frequency: 5          # æ¯5æ¬¡ä¿å­˜ä¸Šä¼ ä¸€æ¬¡
  save_best_models: true       # è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
  best_model_metric: "mean_reward"
```

### é«˜çº§é…ç½®

å‚è€ƒ `cfg/wandb_model_config.yaml` äº†è§£å®Œæ•´é…ç½®é€‰é¡¹ã€‚

## ğŸ“Š wandb ç•Œé¢åŠŸèƒ½

### 1. Artifacts é¢æ¿
- ğŸ“ **æ¨¡å‹ç‰ˆæœ¬**: æ‰€æœ‰è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„æ¨¡å‹ç‰ˆæœ¬
- ğŸ·ï¸ **åˆ«åç®¡ç†**: latest, best, stable ç­‰ç‰ˆæœ¬æ ‡ç­¾
- ğŸ“ˆ **å…ƒæ•°æ®**: å‚æ•°æ•°é‡ã€è®­ç»ƒæ­¥æ•°ã€æ€§èƒ½æŒ‡æ ‡
- ğŸ“‹ **æ¨¡å‹å¡ç‰‡**: è‡ªåŠ¨ç”Ÿæˆçš„æ¨¡å‹æ–‡æ¡£

### 2. æ¨¡å‹æ³¨å†Œè¡¨
- ğŸ¯ **ç”Ÿäº§æ¨¡å‹**: æ ‡è®°ç”¨äºç”Ÿäº§éƒ¨ç½²çš„æ¨¡å‹
- ğŸ“Š **æ€§èƒ½å¯¹æ¯”**: ä¸åŒç‰ˆæœ¬æ¨¡å‹çš„æ€§èƒ½æ¯”è¾ƒ
- ğŸ”„ **ç‰ˆæœ¬æ§åˆ¶**: å®Œæ•´çš„æ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†
- ğŸ‘¥ **å›¢é˜Ÿåä½œ**: æ¨¡å‹å…±äº«å’Œå®¡æ ¸å·¥ä½œæµ

### 3. è®­ç»ƒç›‘æ§
- ğŸ“ˆ **å®æ—¶æŒ‡æ ‡**: è®­ç»ƒæŸå¤±ã€å¥–åŠ±ã€æˆåŠŸç‡ç­‰
- ğŸ¯ **æ¨¡å‹æ€§èƒ½**: ä¸è®­ç»ƒæŒ‡æ ‡å…³è”çš„æ¨¡å‹ç‰ˆæœ¬
- ğŸ“¸ **åª’ä½“æ—¥å¿—**: è®­ç»ƒè¿‡ç¨‹ä¸­çš„å›¾åƒã€è§†é¢‘è®°å½•

## ğŸ› ï¸ å‘½ä»¤è¡Œä½¿ç”¨

### è®­ç»ƒå‘½ä»¤

```bash
# åŸºç¡€è®­ç»ƒ
python train_ppo_with_wandb.py

# æŒ‡å®šé…ç½®æ–‡ä»¶
python train_ppo_with_wandb.py --config-path cfg --config-name wandb_model_config

# ä» wandb artifact æ¢å¤
python train_ppo_with_wandb.py resume_checkpoint="user/navrl-models/model:best"

# ç¦»çº¿æ¨¡å¼è®­ç»ƒ
python train_ppo_with_wandb.py wandb.mode=offline

# ç¦ç”¨ wandb
python train_ppo_with_wandb.py wandb.mode=disabled
```

### æ¨¡å‹ä¸‹è½½å’Œè¯„ä¼°

```bash
# ä¸‹è½½æ¨¡å‹è¿›è¡Œè¯„ä¼°
python -c "
from wandb_model_utils import download_model_from_wandb
model_path = download_model_from_wandb('user/project/model:best')
print(f'Model downloaded to: {model_path}')
"
```

## ğŸ“‹ æœ€ä½³å®è·µ

### 1. æ¨¡å‹ç‰ˆæœ¬å‘½å

```python
# æ¨èçš„åˆ«åä½¿ç”¨
"latest"    # æœ€æ–°æ¨¡å‹
"best"      # æœ€ä½³æ€§èƒ½æ¨¡å‹
"stable"    # ç¨³å®šç‰ˆæœ¬
"v1.0"      # ç‰ˆæœ¬æ ‡è®°
"prod"      # ç”Ÿäº§ç‰ˆæœ¬
```

### 2. æ€§èƒ½é˜ˆå€¼è®¾ç½®

```yaml
model_management:
  upload_conditions:
    min_reward_threshold: 50.0      # åªä¸Šä¼ å¥–åŠ± > 50 çš„æ¨¡å‹
    min_success_rate: 0.8           # åªä¸Šä¼ æˆåŠŸç‡ > 80% çš„æ¨¡å‹
```

### 3. å­˜å‚¨ä¼˜åŒ–

```yaml
model_management:
  upload_frequency: 10              # å‡å°‘ä¸Šä¼ é¢‘ç‡èŠ‚çœå¸¦å®½
  keep_last_n: 3                    # åªä¿ç•™æœ€è¿‘3ä¸ªç‰ˆæœ¬
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **wandb ä¸Šä¼ å¤±è´¥**
   ```python
   # è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API key
   wandb login  # é‡æ–°ç™»å½•
   ```

2. **æ¨¡å‹æ–‡ä»¶è¿‡å¤§**
   ```python
   # è§£å†³æ–¹æ¡ˆï¼šå¯ç”¨æ¨¡å‹å‹ç¼©
   torch.save(state_dict, path, _use_new_zipfile_serialization=False)
   ```

3. **artifact ä¸‹è½½æ…¢**
   ```python
   # è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨æœ¬åœ°ç¼“å­˜
   artifact.download(root="./cache")
   ```

### è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æ£€æŸ¥ wandb è¿æ¥çŠ¶æ€
print(f"wandb run: {wandb.run.name if wandb.run else 'No active run'}")
```

## ğŸ“ˆ æ€§èƒ½ç›‘æ§

### å…³é”®æŒ‡æ ‡è·Ÿè¸ª

```python
# è‡ªåŠ¨è·Ÿè¸ªçš„æŒ‡æ ‡
wandb.log({
    "model/total_parameters": total_params,
    "model/file_size_mb": file_size,
    "train/step": step,
    "eval/mean_reward": reward,
    "best_model/step": best_step
})
```

### è‡ªå®šä¹‰æŒ‡æ ‡

```python
# æ·»åŠ è‡ªå®šä¹‰æŒ‡æ ‡
wandb.log({
    "custom/exploration_rate": exploration_rate,
    "custom/action_diversity": action_entropy,
    "custom/memory_usage": memory_mb
})
```

## ğŸ‰ æ€»ç»“

NavRL çš„ wandb é›†æˆä¸ºä½ æä¾›äº†ï¼š

âœ… **å®Œæ•´çš„æ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†**  
âœ… **è‡ªåŠ¨åŒ–çš„ç‰ˆæœ¬æ§åˆ¶å’Œå…ƒæ•°æ®è·Ÿè¸ª**  
âœ… **æ™ºèƒ½çš„æ€§èƒ½åŸºå‡†æ¨¡å‹ä¿å­˜**  
âœ… **ä¾¿æ·çš„æ¨¡å‹å…±äº«å’Œåä½œ**  
âœ… **ç”Ÿäº§çº§çš„æ¨¡å‹éƒ¨ç½²æ”¯æŒ**  

é€šè¿‡è¿™äº›åŠŸèƒ½ï¼Œä½ å¯ä»¥ï¼š
- ğŸ“Š è½»æ¾è·Ÿè¸ªå’Œæ¯”è¾ƒä¸åŒè®­ç»ƒè¿è¡Œçš„æ¨¡å‹æ€§èƒ½
- ğŸ”„ å¿«é€Ÿå›æ»šåˆ°ä¹‹å‰çš„æœ€ä½³æ¨¡å‹ç‰ˆæœ¬  
- ğŸ‘¥ ä¸å›¢é˜Ÿæˆå‘˜åˆ†äº«è®­ç»ƒå¥½çš„æ¨¡å‹
- ğŸš€ å°†æœ€ä½³æ¨¡å‹éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
- ğŸ“ˆ å»ºç«‹å®Œæ•´çš„æ¨¡å‹æ€§èƒ½åŸºå‡†æ•°æ®åº“

å¼€å§‹ä½¿ç”¨ NavRL + wandb æ¨¡å‹ç®¡ç†ï¼Œè®©ä½ çš„ RL è®­ç»ƒæ›´åŠ ä¸“ä¸šå’Œé«˜æ•ˆï¼